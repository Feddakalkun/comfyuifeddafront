{
  "3": {
    "inputs": {
      "seed": 529776140650680,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "75",
        0
      ],
      "positive": [
        "196",
        0
      ],
      "negative": [
        "195",
        0
      ],
      "latent_image": [
        "205",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "75": {
    "inputs": {
      "strength": 1,
      "model": [
        "145",
        0
      ]
    },
    "class_type": "CFGNorm",
    "_meta": {
      "title": "CFGNorm"
    }
  },
  "88": {
    "inputs": {
      "pixels": [
        "200",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "109": {
    "inputs": {
      "anything": [
        "8",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "145": {
    "inputs": {
      "shift": 3.1000000000000005,
      "model": [
        "149",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "149": {
    "inputs": {
      "model": [
        "217",
        0
      ]
    },
    "class_type": "TorchCompileModelQwenImage",
    "_meta": {
      "title": "TorchCompileModelQwenImage"
    }
  },
  "153": {
    "inputs": {
      "prompt": "take the man and and the woman and have them kiss.",
      "clip": [
        "217",
        1
      ],
      "image1": [
        "200",
        0
      ],
      "image2": [
        "201",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "154": {
    "inputs": {
      "prompt": "",
      "clip": [
        "217",
        1
      ],
      "image1": [
        "200",
        0
      ],
      "image2": [
        "201",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "162": {
    "inputs": {
      "conditioning": [
        "153",
        0
      ],
      "latent": [
        "88",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "163": {
    "inputs": {
      "conditioning": [
        "154",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "171": {
    "inputs": {
      "conditioning": [
        "162",
        0
      ],
      "latent": [
        "172",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "172": {
    "inputs": {
      "pixels": [
        "201",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "175": {
    "inputs": {
      "image": "55555.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Reference"
    }
  },
  "184": {
    "inputs": {
      "any_02": [
        "171",
        0
      ],
      "any_03": [
        "162",
        0
      ]
    },
    "class_type": "Any Switch (rgthree)",
    "_meta": {
      "title": "Any Switch (rgthree)"
    }
  },
  "195": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "163",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "FluxKontextMultiReferenceLatentMethod"
    }
  },
  "196": {
    "inputs": {
      "reference_latents_method": "index_timestep_zero",
      "conditioning": [
        "184",
        0
      ]
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "FluxKontextMultiReferenceLatentMethod"
    }
  },
  "197": {
    "inputs": {
      "unet_name": "qwen_image_edit_2511_fp8_e4m3fn.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "200": {
    "inputs": {
      "width": 480,
      "height": 480,
      "upscale_method": "lanczos",
      "keep_proportion": "total_pixels",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 32,
      "device": "cpu",
      "image": [
        "213",
        0
      ],
      "mask": [
        "213",
        1
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "201": {
    "inputs": {
      "width": 480,
      "height": 480,
      "upscale_method": "lanczos",
      "keep_proportion": "total_pixels",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 32,
      "device": "cpu",
      "image": [
        "175",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "205": {
    "inputs": {
      "any_02": [
        "88",
        0
      ]
    },
    "class_type": "Any Switch (rgthree)",
    "_meta": {
      "title": "Any Switch (rgthree)"
    }
  },
  "209": {
    "inputs": {
      "lora_name": "qwen-image-lightning\\Qwen-Image-Lightning-8steps-V2.0.safetensors",
      "strength_model": 1,
      "model": [
        "197",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "213": {
    "inputs": {
      "image": "IMG_20230704_144149094_HDR (1).jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "214": {
    "inputs": {
      "images": [
        "8",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "215": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_phlhg_00011_.png&type=temp&subfolder=&rand=0.5094219523586826"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_phlhg_00012_.png&type=temp&subfolder=&rand=0.5248528210959628"
          }
        ]
      },
      "image_a": [
        "8",
        0
      ],
      "image_b": [
        "200",
        0
      ]
    },
    "class_type": "Image Comparer (rgthree)",
    "_meta": {
      "title": "Image Comparer (rgthree)"
    }
  },
  "217": {
    "inputs": {
      "lora_01": "Qwen_Snofs_1_3.safetensors",
      "strength_01": 1,
      "lora_02": "None",
      "strength_02": 1,
      "lora_03": "None",
      "strength_03": 1,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "209",
        0
      ],
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)",
    "_meta": {
      "title": "Lora Loader Stack (rgthree)"
    }
  },
  "218": {
    "inputs": {
      "reference_latents_method": "offset"
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "FluxKontextMultiReferenceLatentMethod"
    }
  },
  "219": {
    "inputs": {
      "reference_latents_method": "offset"
    },
    "class_type": "FluxKontextMultiReferenceLatentMethod",
    "_meta": {
      "title": "FluxKontextMultiReferenceLatentMethod"
    }
  },
  "220": {
    "inputs": {
      "text": "=== DOWNLOAD REPORT ===\nTotal files: 6\nSuccessful downloads: 1\nAlready existed: 5\nInterrupted: 0\nFailed: 0\nMax concurrent: 3\nSpeed limit: Unlimited\nResume enabled: True\nValidation enabled: False\nAuto-organize: False\n\nDetails:\nâœ“ qwen_2.5_vl_7b_fp8_scaled.safetensors: Already exists (8.74 GB)\nâœ“ qwen_image_vae.safetensors: Already exists (242.05 MB)\nâœ“ Qwen-Image-2512-Lightning-4steps-V1.0-bf16.safetensors: Already exists (810.25 MB)\nâœ“ Qwen-Image-2512-Lightning-8steps-V1.0-bf16.safetensors: Already exists (810.25 MB)\nâœ“ Qwen_Snofs_1_3.safetensors: Already exists (585.40 MB)\nâœ“ qwen_image_edit_2511_fp8_e4m3fn.safetensors: Downloaded successfully to diffusion_models/ (19.03 GB)",
      "anything": [
        "221",
        0
      ]
    },
    "class_type": "easy showAnything",
    "_meta": {
      "title": "Show Any"
    }
  },
  "221": {
    "inputs": {
      "download_links": "https://huggingface.co/drbaph/Qwen-Image-Edit-2511-FP8/resolve/main/qwen_image_edit_2511_fp8_e4m3fn.safetensors?download=true diffusion_models\nhttps://huggingface.co/Comfy-Org/Qwen-Image/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors text_encoders\nhttps://huggingface.co/Comfy-Org/Qwen-Image/resolve/main/split_files/vae/qwen_image_vae.safetensors vae\nhttps://huggingface.co/lightx2v/Qwen-Image-2512-Lightning/resolve/main/Qwen-Image-2512-Lightning-4steps-V1.0-bf16.safetensors?download=true loras\nhttps://huggingface.co/lightx2v/Qwen-Image-2512-Lightning/resolve/main/Qwen-Image-2512-Lightning-8steps-V1.0-bf16.safetensors?download=true loras\nhttps://huggingface.co/trungzpham/Qwen/resolve/main/Qwen_Snofs_1_3.safetensors?download=true loras",
      "auto_download": true,
      "max_concurrent_downloads": 3,
      "max_download_speed_mbps": 0,
      "enable_resume": true,
      "validate_files": false,
      "enable_notifications": true,
      "auto_organize": false,
      "hf_token": ""
    },
    "class_type": "HuggingFaceDownloader",
    "_meta": {
      "title": "ðŸ¤— HuggingFace Model Downloader Pro"
    }
  }
}