{
    "3": {
        "inputs": {
            "seed": 0,
            "steps": 20,
            "cfg": 7,
            "sampler_name": "euler",
            "scheduler": "normal",
            "denoise": 1,
            "model": [
                "126",
                0
            ],
            "positive": [
                "6",
                0
            ],
            "negative": [
                "7",
                0
            ],
            "latent_image": [
                "13",
                0
            ]
        },
        "class_type": "KSampler"
    },
    "6": {
        "inputs": {
            "text": [
                "33",
                0
            ],
            "clip": [
                "18",
                0
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "7": {
        "inputs": {
            "text": [
                "34",
                0
            ],
            "clip": [
                "18",
                0
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "8": {
        "inputs": {
            "samples": [
                "3",
                0
            ],
            "vae": [
                "17",
                0
            ]
        },
        "class_type": "VAEDecode"
    },
    "9": {
        "inputs": {
            "filename_prefix": "FaceID/consistent",
            "images": [
                "8",
                0
            ]
        },
        "class_type": "SaveImage"
    },
    "13": {
        "inputs": {
            "width": 832,
            "height": 1216,
            "batch_size": 1
        },
        "class_type": "EmptySD3LatentImage"
    },
    "16": {
        "inputs": {
            "unet_name": "z_image_turbo_bf16.safetensors",
            "weight_dtype": "default"
        },
        "class_type": "UNETLoader"
    },
    "17": {
        "inputs": {
            "vae_name": "z-image-vae.safetensors"
        },
        "class_type": "VAELoader"
    },
    "18": {
        "inputs": {
            "clip_name": "qwen_3_4b.safetensors",
            "type": "lumina2",
            "device": "default"
        },
        "class_type": "CLIPLoader"
    },
    "33": {
        "inputs": {
            "string": "a beautiful woman, realistic, high quality"
        },
        "class_type": "String Literal"
    },
    "34": {
        "inputs": {
            "string": "worst quality, low quality, bad anatomy"
        },
        "class_type": "String Literal"
    },
    "126": {
        "inputs": {
            "PowerLoraLoaderHeaderWidget": {
                "type": "PowerLoraLoaderHeaderWidget"
            },
            "âž• Add Lora": "",
            "model": [
                "16",
                0
            ],
            "clip": [
                "18",
                0
            ]
        },
        "class_type": "Power Lora Loader (rgthree)"
    }
}